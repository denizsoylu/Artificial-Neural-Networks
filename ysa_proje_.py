# -*- coding: utf-8 -*-
"""YSA-PROJE-.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p685VRJ0Eal2zvWe1uDj6jiU2zhhw9qM
"""

# Gerekli kütüphaneleri yükleme
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Kaggle veri setini yükleme (Colab için gerekli ayarlarla)
import kagglehub
sercanyesiloz_hitters_path = kagglehub.dataset_download('sercanyesiloz/hitters')

# Veri setini okuma
data_path = f"{sercanyesiloz_hitters_path}/Hitters.csv"
data = pd.read_csv(data_path)

# Eksik verileri kontrol etme ve doldurma
data['Salary'].fillna(data['Salary'].median(), inplace=True)

# Kategorik değişkenleri sayısal değerlere dönüştürme
categorical_columns = ['League', 'Division', 'NewLeague']
data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)

# Özellikler (X) ve hedef değişkeni (y) ayırma
X = data.drop(columns=['Salary'])
y = data['Salary']

# Veriyi eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Veriyi standartlaştırma
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Farklı aktivasyon fonksiyonları ve nöron sayıları denemek için fonksiyon
def build_and_train_model(activation_fn, neuron_counts, weight_range=(-0.1, 0.1), bias_range=(-0.1, 0.1)):
    model = Sequential()
    model.add(Dense(neuron_counts[0], input_dim=X_train_scaled.shape[1], activation=activation_fn))
    for neurons in neuron_counts[1:]:
        model.add(Dense(neurons, activation=activation_fn))
    model.add(Dense(1))

    # Ağırlık ve biasları rastgele başlatma
    for layer in model.layers:
        if hasattr(layer, 'kernel_initializer'):
            weight_shape = layer.get_weights()[0].shape
            bias_shape = layer.get_weights()[1].shape
            random_weights = np.random.uniform(weight_range[0], weight_range[1], weight_shape)
            random_biases = np.random.uniform(bias_range[0], bias_range[1], bias_shape)
            layer.set_weights([random_weights, random_biases])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    early_stopping = EarlyStopping(monitor='val_mae', patience=50, restore_best_weights=True)
    history = model.fit(X_train_scaled, y_train,
                        validation_data=(X_test_scaled, y_test),
                        epochs=300, batch_size=32,
                        callbacks=[early_stopping], verbose=0)
    return model, history

# Aktivasyon fonksiyonları ve nöron kombinasyonları
activation_functions = ['relu', 'sigmoid', 'tanh', 'elu', 'selu', 'softplus', 'softsign']
neuron_combinations = [
    [32, 16, 8],
    [64, 32, 16],
    [128, 64, 32],
    [256, 128, 64]
]

# En iyi sonucu bulmak için model eğitimi ve performans kaydı
best_model = None
best_mae = float('inf')
results = []

# Denemeler için ağırlık ve bias aralıkları
deneme_sayisi = 5
weight_ranges = [(-0.1, 0.1), (-0.2, 0.2), (-0.05, 0.05), (-0.3, 0.3), (-0.01, 0.01)]
bias_ranges = [(-0.1, 0.1), (-0.2, 0.2), (-0.05, 0.05), (-0.3, 0.3), (-0.01, 0.01)]

for activation_fn in activation_functions:
    for neuron_counts in neuron_combinations:
        for weight_range, bias_range in zip(weight_ranges, bias_ranges):
            for _ in range(deneme_sayisi):
                model, history = build_and_train_model(activation_fn, neuron_counts, weight_range, bias_range)

                # Performans değerlendirme
                y_pred = model.predict(X_test_scaled)
                mae = mean_absolute_error(y_test, y_pred)
                results.append((activation_fn, neuron_counts, weight_range, bias_range, mae))

                print(f"Activation: {activation_fn}, Neurons: {neuron_counts}, Weight Range: {weight_range}, Bias Range: {bias_range}, MAE: {mae:.2f}")

                if mae < best_mae:
                    best_mae = mae
                    best_model = model

# En iyi sonucu yazdırma
best_result = sorted(results, key=lambda x: x[4])[0]
best_activation, best_neurons, best_weight_range, best_bias_range, _ = best_result
print(f"Best Activation: {best_activation}, Best Neurons: {best_neurons}, Best Weight Range: {best_weight_range}, Best Bias Range: {best_bias_range}, Best MAE: {best_mae:.2f}")

# En iyi modelin tahminleri
y_best_pred = best_model.predict(X_test_scaled)
r2 = r2_score(y_test, y_best_pred)
print(f"Best Model R2 Score: {r2:.2f}")